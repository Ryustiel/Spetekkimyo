{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from IPython.display import HTML, display\n",
    "try:\n",
    "    (notebook_dir, e)\n",
    "except:\n",
    "    e = \"a --- b\"\n",
    "    notebook_dir = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding = {\n",
    "    \"space\": 275,  # Standard space width\n",
    "    \"ks_\": -180,\n",
    "    \"ts_\": -380,\n",
    "    \"ka_\": -280,\n",
    "    \"ko_\": -390,\n",
    "    \"ta_\": -250,\n",
    "    \"to_\": -250,\n",
    "    \"tb_\": -250,\n",
    "    \"tc_\": -280,\n",
    "    \"tuR_\": -340,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nommage des fichiers : \n",
    "* \"ta_\" suffit si la lettre attendue est \\_a; a_ attend un a à gauche (ou une lettre compatible), pareil dans l'autre sens.\n",
    "* uL et uR (Left; Right par rapp à la direction vers laquelle l'arche pointe); bL et bR (direction de la pointe pour les heads) ; les autres lesttres sont en a_left; a_right; etc\n",
    "* Les autres glyphes sont notés comme leur composante principale (par ex \"ks\") puis un commentaire : ks_above_t\n",
    "\n",
    "### TODO :\n",
    "* Découper uL et uR en deux formes, avec des connecteurs \"avant\" et \"après\" pour interfacer avec fa_ et n. Revoir le design de la lettre... Créer les jonctions (t, s) en un glyph bien défini.\n",
    "* Voyelles précédent les clusters (et f)\n",
    "* Formes T basses (mécanique \"d\", \"g\" et \"s+...\")\n",
    "* Diacritiques (i, l, h)\n",
    "* Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea = '''\n",
    "\n",
    "table GDEF {\n",
    "    GlyphClassDef\n",
    "        [], # Base glyphs\n",
    "        [], # Ligature glyphs\n",
    "        [j h _i_ _j _h ji_ hi_ la_ lo_ _al _ol _sla_ _slp_ _bRl _bLl lbR_ lbL_], # Mark glyphs\n",
    "        []; # Component glyphs\n",
    "} GDEF;\n",
    "\n",
    "feature ccmp {\n",
    "    script DFLT;\n",
    "    language dflt required;\n",
    "    script latn;\n",
    "    language dflt required;\n",
    "\n",
    "    ######################################################################### 1 CHOIX CONTEXTUEL\n",
    "    \n",
    "    lookup ETAPE_1_REPLACEMENTS {\n",
    "\n",
    "        sub m by n;\n",
    "        \n",
    "    } ETAPE_1_REPLACEMENTS;\n",
    "    \n",
    "    ################################\n",
    "    \n",
    "    lookup ETAPE_1_PRE_MERGE {\n",
    "        \n",
    "        sub j i by ji;\n",
    "        sub j j by ji;\n",
    "        sub h i by hi;\n",
    "        sub h j by hi;\n",
    "        \n",
    "        # Lettre S\n",
    "        \n",
    "        sub s i by si_;\n",
    "        \n",
    "    } ETAPE_1_PRE_MERGE;\n",
    "    \n",
    "    #################################\n",
    "    \n",
    "    lookup ETAPE_1_FLOTTANTES {  # Décide si les lettres flottantes doivent devenir des diacritiques ou non\n",
    "\n",
    "        # IJ positioning\n",
    "        \n",
    "        sub s i' by s _i_;\n",
    "\n",
    "        sub [a o e p y bL bR uL uR n] i' [a o e p y bL bR uL uR n] by _i_;  # i becomes a diacritic\n",
    "        sub i' [n] by _i_;\n",
    "        \n",
    "        sub ji' [n a o e p y bL bR uL uR n] by ji_;  # ji becomes a diacritic if followed by something\n",
    "        sub hi' [n a o e p y bL bR uL uR n] by hi_; \n",
    "        \n",
    "        sub j' [a o e p y bL bR uL uR] by j;\n",
    "        sub j' by _j;  # If not followed\n",
    "        \n",
    "        # H positioning\n",
    "        \n",
    "        sub h' [a o e p y bL bR uL uR] by h;  # Check if followed by something\n",
    "        sub [a o e p y bL bR uL uR] h' by _h;\n",
    "\n",
    "        # L positioning\n",
    "        \n",
    "        sub [s t d] l' [a e bR uR] by _sla_;  # s t k precedence\n",
    "        sub [s t d] l' [bL uL p] by _slp_;\n",
    "        \n",
    "        sub l' [a e] by la_;  # If followed by something\n",
    "        sub l' [o y] by lo_;\n",
    "        sub l' [bL uL p] by lbL_;\n",
    "        sub l' [bR uR] by lbR_;\n",
    "        \n",
    "        sub [a e] l' by _al;  # If not followed\n",
    "        sub [o y] l' by _ol;\n",
    "        sub [bL uL p] l' by _bLl;\n",
    "        sub [bR uR] l' by _bRl;\n",
    "        \n",
    "    } ETAPE_1_FLOTTANTES;\n",
    "    \n",
    "    #################################\n",
    "\n",
    "    lookup ETAPE_1_NON_FLOTTANTES {  # Choix forme contextuelle de base\n",
    "        \n",
    "        lookupflag IgnoreMarks;\n",
    "\n",
    "        # Lettre F\n",
    "\n",
    "        sub [a p] f' by fa_;\n",
    "        sub [o e] f' by fo_;\n",
    "\n",
    "        sub f' [a c u] by fa_;\n",
    "        sub k' [a c u b] by ka_;\n",
    "\n",
    "        sub f' [o b] by fo_;  # This isnt optimal but it's easier to read\n",
    "        sub k' [o b] by ko_;\n",
    "\n",
    "        # Lettre B\n",
    "\n",
    "        sub [o n fo_] b' by bR;\n",
    "        sub b' by bL;\n",
    "\n",
    "        # Lettre U\n",
    "\n",
    "        sub [t s] u' by uR;  # Ignore next letter\n",
    "        sub [n] u' by uL;  \n",
    "        sub u' [a e p o b c y n] by uR;\n",
    "        sub u' [f] [a e p c u n] by uR;\n",
    "        sub u' by uL;\n",
    "\n",
    "    } ETAPE_1_NON_FLOTTANTES;\n",
    "\n",
    "    ######################################################################### 2 DECOMPOSITION FUSION\n",
    "    \n",
    "    lookup ETAPE_2_DECOMPOSITION {  # Decoupe tous les caracteres en composants\n",
    "\n",
    "        lookupflag IgnoreMarks;\n",
    "\n",
    "        # Explicit 2 Parts\n",
    "\n",
    "        sub a by a_ _a;\n",
    "        sub o by o_ _o;\n",
    "        sub e by a_ _e;\n",
    "        sub p by a_ _p;\n",
    "        sub y by o_ _y;\n",
    "        sub c by c_ _c;\n",
    "        sub s by s_ _s;\n",
    "        \n",
    "        # Implicit 2 Parts\n",
    "        \n",
    "        sub si_ by si_ _s;\n",
    "        \n",
    "        # B\n",
    "        \n",
    "        sub bR by o_ _b;\n",
    "        sub bL by b_ _o;\n",
    "\n",
    "    } ETAPE_2_DECOMPOSITION;\n",
    "\n",
    "    #################################\n",
    "\n",
    "    lookup ETAPE_2_FUSION {  # Fusionne les composants des que possible\n",
    "\n",
    "        lookupflag IgnoreMarks;\n",
    "\n",
    "        # AO OA\n",
    "\n",
    "        sub _a o_ by _ao_;\n",
    "        sub _o a_ by _oa_;\n",
    "\n",
    "        sub _oa_ a_ by _oa_;\n",
    "        sub _ao_ o_ by _ao_;\n",
    "\n",
    "        # S\n",
    "\n",
    "        sub _s a_ by _sa_;\n",
    "        sub _s b_ by _sb_;\n",
    "        sub _s c_ by _sc_;\n",
    "        \n",
    "        sub _s uR by uR;\n",
    "\n",
    "        # K\n",
    "\n",
    "        sub k s_ by ks_;\n",
    "\n",
    "        # T\n",
    "\n",
    "        sub t s_ by ts_;\n",
    "        sub t a_ by ta_;\n",
    "        sub t o_ by to_;\n",
    "        sub t b_ by tb_;\n",
    "        sub t c_ by tc_;\n",
    "\n",
    "    } ETAPE_2_FUSION;\n",
    "\n",
    "    ######################################################################### 3 ESTHETIQUE\n",
    "\n",
    "    lookup ETAPE_3_ESTHETIQUE {  # Applique les formes purement esthétiques\n",
    "\n",
    "        lookupflag IgnoreMarks;\n",
    "        \n",
    "        # HORIZONTAL CONNECTORS\n",
    "\n",
    "        sub [n fo_] a_' by _na_;\n",
    "        sub [n fo_] c_' by _nc_;\n",
    "        sub [n fa_] o_' by _no_;\n",
    "        sub [_a _p] b_' by _bn_;\n",
    "        \n",
    "        sub _c' [n fo_] by _cn_;\n",
    "        sub _a' [n fo_] by _an_;\n",
    "        sub _o' [n fa_] by _on_;\n",
    "        \n",
    "        sub _p' [n fo_] by _pn_;\n",
    "        sub _e' [n fo_ s_ si_] by _en_;\n",
    "        sub _b' [n fa_] by _bn_;\n",
    "\n",
    "        # U FORMS\n",
    "\n",
    "        sub ka_ uR' by uR_after_high;\n",
    "        sub _s uR' by uR_after_high;\n",
    "\n",
    "        sub n uL' by uL_after_n;\n",
    "        sub [ka_ fa_] uL' by uL_after_high;\n",
    "        \n",
    "        sub uR' n by uR_before_n;\n",
    "        sub uR' [fa_] by uR_before_high;\n",
    "\n",
    "        sub t' uR by tuR_;\n",
    "\n",
    "        # B ENDING FORMS\n",
    "\n",
    "        sub [fo_] b_' _o' [a_ o_ s_ si_] by b_; # Ignoring certain combinations\n",
    "        sub _e' b_' _o' by b_ending;\n",
    "        sub _o o_' _b' by b_ending;  # _b implies it is not connected to the next letter\n",
    "        # TODO : Mix b_ending to bs, bn, bf, bt, bk depending on the consonnant that follows\n",
    "        # TODO : Ignore b_ending if followed by any other shit\n",
    "\n",
    "        # S ENDING FORMS\n",
    "\n",
    "        sub [_a n fa_] s_' _s' by s_after_high;\n",
    "        sub [fo_ _en_] s_' _s' by s_after_low;\n",
    "        \n",
    "        sub _o' s_' _s' by os_ending;\n",
    "        sub _c' s_' _s' by cs_ending;\n",
    "        sub _p' s_' _s' by ps_ending;\n",
    "        sub _y' s_' _s' by ys_ending;\n",
    "\n",
    "    } ETAPE_3_ESTHETIQUE;\n",
    "\n",
    "    ######################################################################### 4 KERNING\n",
    "\n",
    "    lookup ETAPE_4_KERNING {\n",
    "\n",
    "        lookupflag IgnoreMarks;\n",
    "\n",
    "        # MERGE VOYELLE -80\n",
    "\n",
    "        pos [_a _o] [a_ o_] -80;\n",
    "        pos _p [a_ o_] -90;\n",
    "        pos _o b_ending -5;\n",
    "\n",
    "        # VOYELLE U\n",
    "\n",
    "        pos tuR_ [uR uR_before_n uR_before_high] -160;\n",
    "        pos [s_ si_] [uR uR_before_n uR_before_high] -120;\n",
    "\n",
    "        # MERGE VOYELLE S -80\n",
    "\n",
    "        pos [_s] [o_] -80;\n",
    "        pos _a s_after_high -80;\n",
    "        pos [fo_ _en_] s_after_low -80;\n",
    "\n",
    "        pos [n fa_] s_after_high -5;\n",
    "\n",
    "        # MERGE VOYELLE F N\n",
    "\n",
    "        pos [_a _o _p _an_ _on_ _cn_ _pn_ _bn_ _en_] [fa_ fo_ n _bn_] -20;\n",
    "        pos [fa_ fo_ n] [a_ o_ _na_ _no_ _nc_] -20;\n",
    "\n",
    "        # POSITIONNEMENT K T VOYELLE\n",
    "\n",
    "        pos ka_ c_ -40;\n",
    "\n",
    "        # MERGE K T S\n",
    "        \n",
    "        \n",
    "\n",
    "    } ETAPE_4_KERNING;\n",
    "    \n",
    "    #################################\n",
    "\n",
    "    lookup ETAPE_4_DIACRITIC_KERNING {\n",
    "        \n",
    "        # POSITIONNEMENT IJHL NON DIACRITIQUES\n",
    "\n",
    "        pos i [ts_ ta_] <-80 480 0 0>;\n",
    "        pos i [s_ si_] <-80 420 0 0>;\n",
    "        pos [i ji] [a_ o_] <-80 0 0 0>;\n",
    "        \n",
    "        # VOYELLE I\n",
    "        \n",
    "        pos _i_ [n] <-260 360 0 0>;  # x-advance y-advance x-placement y-placement (placement moves the glyph)\n",
    "        pos _i_ [a_ o_ _na_ _no_ _ao_ _oa_ _a _o] <-290 -260 0 0>;\n",
    "\n",
    "        # FLOTTANTES JH\n",
    "\n",
    "        # pos [s_ si_] [j h] <180 0 0 0>;\n",
    "        pos [j h ji_ hi_] [n] <-100 360 0 0>;\n",
    "        pos [j h ji_ hi_] [a_ o_ _na_ _no_] <180 360 0 0>;\n",
    "        pos [j h ji_ hi_] [_a _o _oa_ _ao_] <-100 360 0 0>;\n",
    "        \n",
    "    } ETAPE_4_DIACRITIC_KERNING;\n",
    "    \n",
    "    #################################\n",
    "    \n",
    "    lookup ETAPE_4_CONSTANT_KERNING {\n",
    "\n",
    "        # POSITIONNEMENT S\n",
    "        \n",
    "        pos s_ <0 0 -80 0>;\n",
    "        pos si_ <0 0 -140 0>;\n",
    "\n",
    "        # POSITIONNEMENT IJH\n",
    "        \n",
    "        pos [_j _h] <-375 -260 0 0>;\n",
    "        pos [i ji hi] <60 100 40 0>;\n",
    "        \n",
    "        # POS L\n",
    "        \n",
    "        pos [la_ lo_ lbR_ lbL_] <0 420 0 0>;\n",
    "        pos [_slp_ _sla_] <-260 420 0 0>;\n",
    "        pos [_al _ol] <-550 -140 0 0>;\n",
    "\n",
    "    } ETAPE_4_CONSTANT_KERNING;\n",
    "\n",
    "} ccmp;\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 103 glyphs: a a_ b bL bR b_ b_ending c cs_ending c_ d d_ e f fa_ fo_ h hi hi_ i j ji ji_ k ka_ ko_ ks ks_ l la_ lbL_ lbR_ lo_ m n o os_ending o_ p ps_ending s si_ space s_ s_after_high s_after_low t ta_ tb_ tc_ tks_ tk_high tk_low to_ ts_ tuR_ u uL uL_after_high uL_after_n uR uR_after_high uR_before_high uR_before_n y ys_ending _a _al _an_ _ao_ _b _bLl _bn_ _bRl _c _cn_ _da_ _e _en_ _fc _h _i_ _j _na_ _nc_ _no_ _o _oa_ _ol _on_ _p _pn_ _s _sa_ _sb_ _sc_ _si_ _sj_ _sla_ _slp_ _ti_ _y _yn_\n",
      "Imported features\n",
      "Font generated at d:\\Github\\spetekkimyo\\output\\test.otf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm sorry this file is too complex for me to understand (or is erroneous, or is empty)\n"
     ]
    }
   ],
   "source": [
    "try: counter += 1\n",
    "except: counter = 0\n",
    "if not os.getcwd().endswith('bin'): \n",
    "    notebook_dir = os.getcwd()  # Actual working directory\n",
    "    %cd \".\\spetekkimyo\\ffpython\\bin\\\"\n",
    "json.dump(padding, open(f'{notebook_dir}\\\\spetekkimyo\\\\input\\\\padding.json', 'w'))\n",
    "with open(f'{notebook_dir}\\\\spetekkimyo\\\\input\\\\features.fea', 'w') as f: f.write(fea)\n",
    "!\"ffpython.exe\" \"..\\..\\generate.py\" \"{notebook_dir}\\output\\test.otf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = \"\"\"\n",
    "<span class=\"ss\">na ku </span> pb\n",
    "\"\"\" # TODO : jubn (predefined _bn and _bf charecters) ; da - sta - sda ; fta fsa fka ; ga - ska ; spacing inter mots et \"spe\" ; jonction u + autres lettres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>p {font-size: 120px;} @font-face {src:url('./output/test.otf?version=89');font-family:'test';} .ss {font-family:'test';}</style>\n",
       "<p>\n",
       "<span class=\"ss\">na ku </span> pb\n",
       "</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "html = \"\"\"<style>p {font-size: 120px;} @font-face {src:url('./output/test.otf?version=%s');font-family:'test';} .ss {font-family:'test';}</style>\n",
    "<p>%s</p>\"\"\" % (counter, e)\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guidelines\n",
    "\n",
    "Epaisseur du trait : 80\n",
    "\n",
    "Largeur : **550** (275) -- consonants 320 - 440 (max d'épaisseur) - 550 (pointe droite)\n",
    "\n",
    "Hauteur standard : 320 -- max = 730 -- low = -240\n",
    "\n",
    "Départ : h=-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spetekkimyo-HTARb5-U-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
